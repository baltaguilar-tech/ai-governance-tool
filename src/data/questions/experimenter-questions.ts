// =============================================================================
// EXPERIMENTER BANK — 60 questions
// For orgs just starting to explore AI tools. Focus: awareness, first steps,
// basic practices. Language is accessible; avoids technical jargon.
// =============================================================================

import { AssessmentQuestion } from '@/types/assessment';

export const EXPERIMENTER_QUESTIONS: AssessmentQuestion[] = [
  // --- Shadow AI & Visibility (10) ---
  {
    id: 'shadow-e-1',
    dimension: 'shadowAI',
    text: 'Are you aware of which AI tools employees are currently using at work?',
    helpText: 'Most organizations discover AI tool usage is already happening before any formal policy exists. Understanding your starting point is the first governance step.',
    type: 'radio',
    options: [
      { label: 'Not assessed — we haven’t looked into this', value: 100 },
      { label: 'We have a rough sense but haven’t documented it', value: 65 },
      { label: 'We’ve informally asked around and have a partial picture', value: 35 },
      { label: 'We know what’s being used and by which teams', value: 0 },
    ],
  },
  {
    id: 'shadow-e-2',
    dimension: 'shadowAI',
    text: 'Do employees know whether they need permission before using a new AI tool?',
    helpText: 'Without clear expectations, employees default to using whatever works. Simply communicating a basic expectation reduces shadow AI significantly.',
    type: 'radio',
    options: [
      { label: 'No guidance has been given', value: 100 },
      { label: 'Some employees know informally, most don’t', value: 65 },
      { label: 'Most employees are aware there’s an expectation', value: 35 },
      { label: 'All employees know the expectation and where to go', value: 0 },
    ],
  },
  {
    id: 'shadow-e-3',
    dimension: 'shadowAI',
    text: 'Does your organization have a list of AI tools that employees are allowed to use?',
    helpText: 'An approved tool list (even an informal one) gives employees a default answer and reduces unsanctioned tool adoption.',
    type: 'radio',
    options: [
      { label: 'No approved list exists', value: 100 },
      { label: 'Informally known but not written down', value: 65 },
      { label: 'Written list, shared with some teams', value: 35 },
      { label: 'Written approved list, accessible to all employees', value: 0 },
    ],
  },
  {
    id: 'shadow-e-4',
    dimension: 'shadowAI',
    text: 'Are employees using AI tools through personal accounts rather than company accounts?',
    helpText: 'Personal account usage means data leaves the organization with no visibility or control. This is one of the highest-risk shadow AI patterns.',
    type: 'radio',
    options: [
      { label: 'Yes, and we have no visibility into it', value: 100 },
      { label: 'Probably yes, but we haven’t formally addressed it', value: 65 },
      { label: 'We’ve asked employees not to, but don’t enforce it', value: 35 },
      { label: 'Employees use company accounts for approved tools', value: 0 },
    ],
  },
  {
    id: 'shadow-e-5',
    dimension: 'shadowAI',
    text: 'Does your IT team get notified when employees sign up for new AI services?',
    helpText: 'Most AI tools are SaaS subscriptions purchased with a credit card or signed up with a company email — both routes bypass IT. Visibility starts with notification.',
    type: 'radio',
    options: [
      { label: 'No, IT finds out after the fact (or never)', value: 100 },
      { label: 'Occasionally, through informal channels', value: 65 },
      { label: 'Sometimes — depends on how it’s purchased', value: 35 },
      { label: 'Yes, there’s a process and IT is looped in', value: 0 },
    ],
  },
  {
    id: 'shadow-e-6',
    dimension: 'shadowAI',
    text: 'Have you had any leadership discussion about how AI tools are being used in your organization?',
    helpText: 'Leadership awareness is the prerequisite for any governance investment. If AI hasn’t come up at the leadership level, governance won’t happen.',
    type: 'radio',
    options: [
      { label: 'Not yet', value: 100 },
      { label: 'Briefly mentioned but not a focus', value: 65 },
      { label: 'It’s been discussed and there’s general awareness', value: 35 },
      { label: 'Leadership is engaged and driving the conversation', value: 0 },
    ],
  },
  {
    id: 'shadow-e-7',
    dimension: 'shadowAI',
    text: 'Do you know if employees are sharing confidential company information with AI tools?',
    helpText: 'Employees regularly paste customer data, financial information, and internal documents into tools like ChatGPT without realizing the risk. Knowing whether this is happening is the first step.',
    type: 'radio',
    options: [
      { label: 'Not assessed — we haven’t asked or checked', value: 100 },
      { label: 'We suspect it’s happening but haven’t confirmed', value: 65 },
      { label: 'We’ve raised awareness but don’t have visibility', value: 35 },
      { label: 'We have guidelines and employees know what not to share', value: 0 },
    ],
  },
  {
    id: 'shadow-e-8',
    dimension: 'shadowAI',
    text: 'Does anyone in your organization have a clear responsibility for overseeing AI tool adoption?',
    helpText: 'Without an owner, AI governance is everyone’s problem and no one’s job. Even a part-time AI coordinator makes a measurable difference.',
    type: 'radio',
    options: [
      { label: 'No one has this responsibility', value: 100 },
      { label: 'It’s unclear who owns it', value: 65 },
      { label: 'Someone is loosely responsible alongside other duties', value: 35 },
      { label: 'There’s a clear owner with defined responsibilities', value: 0 },
    ],
  },
  {
    id: 'shadow-e-9',
    dimension: 'shadowAI',
    text: 'Are you aware that existing tools your organization uses (Zoom, Slack, Microsoft 365, Salesforce) have been adding AI features by default?',
    helpText: 'Major SaaS vendors have embedded AI features that may be on by default. These features can process company data in new ways without IT or compliance review.',
    type: 'radio',
    options: [
      { label: 'Not aware of this', value: 100 },
      { label: 'Aware of some but haven’t reviewed them', value: 65 },
      { label: 'Reviewed some AI features in existing tools', value: 35 },
      { label: 'Actively reviewing all vendor AI features as they’re released', value: 0 },
    ],
  },
  {
    id: 'shadow-e-10',
    dimension: 'shadowAI',
    text: 'Have you communicated any basic guidance to employees about responsible AI use at work?',
    helpText: 'Even a simple "don’t paste customer data into AI tools" email starts building a governance culture. Only 18.5% of employees report being aware of any company AI policy.',
    type: 'radio',
    options: [
      { label: 'No guidance has been communicated', value: 100 },
      { label: 'Mentioned verbally in a meeting or two', value: 65 },
      { label: 'Written guidance shared with some teams', value: 35 },
      { label: 'Clear written guidance distributed to all employees', value: 0 },
    ],
  },

  // --- Vendor AI Risk (10) ---
  {
    id: 'vendor-e-1',
    dimension: 'vendorRisk',
    text: 'Do you know which of your current software vendors have added AI features to their products?',
    helpText: 'Salesforce, Microsoft, Zoom, Slack, and hundreds of other vendors are embedding AI into existing products. Your AI footprint is likely larger than you think.',
    type: 'radio',
    options: [
      { label: 'No, we haven’t looked at this', value: 100 },
      { label: 'We’re aware of a few, but haven’t done a full review', value: 65 },
      { label: 'We’ve reviewed our major vendors', value: 35 },
      { label: 'Yes, we track AI features across all key vendors', value: 0 },
    ],
  },
  {
    id: 'vendor-e-2',
    dimension: 'vendorRisk',
    text: 'Have you read the data usage and AI sections of your key vendor contracts or terms of service?',
    helpText: 'Many vendors include broad rights to use customer data for AI model training in their standard terms. Most organizations have never read these sections.',
    type: 'radio',
    options: [
      { label: 'No, we haven’t reviewed these sections', value: 100 },
      { label: 'We’ve skimmed them for a couple of key vendors', value: 65 },
      { label: 'We’ve reviewed most major vendor contracts', value: 35 },
      { label: 'Yes, we review AI/data sections for all key vendors', value: 0 },
    ],
  },
  {
    id: 'vendor-e-3',
    dimension: 'vendorRisk',
    text: 'Do you know whether your vendors are using your company data to train their AI models?',
    helpText: 'Many AI vendors use customer data to improve their models unless you opt out. This is one of the most common and least-understood AI vendor risks.',
    type: 'radio',
    options: [
      { label: "Not assessed — we haven’t asked", value: 100 },
      { label: 'We assume they are, haven’t checked', value: 65 },
      { label: 'We’ve asked a couple of key vendors', value: 35 },
      { label: 'We know for our main vendors and have opted out where needed', value: 0 },
    ],
  },
  {
    id: 'vendor-e-4',
    dimension: 'vendorRisk',
    text: 'Have you reviewed the privacy settings for AI features in any of your existing software subscriptions?',
    helpText: 'Most AI features have privacy settings that default to maximum data sharing. Reviewing and adjusting these is a quick win for most organizations.',
    type: 'radio',
    options: [
      { label: 'No, we haven’t done this', value: 100 },
      { label: 'Checked for one or two tools', value: 65 },
      { label: 'Reviewed settings for most major tools', value: 35 },
      { label: 'Yes, privacy settings reviewed for all key tools', value: 0 },
    ],
  },
  {
    id: 'vendor-e-5',
    dimension: 'vendorRisk',
    text: 'Do you know where (which country or region) your key vendors store and process your data?',
    helpText: 'Data residency affects which privacy laws apply to your data. Especially important if you operate in or serve customers in the EU or other regulated regions.',
    type: 'radio',
    options: [
      { label: 'Not assessed — data processing location unknown', value: 100 },
      { label: 'Know for our most critical vendor(s) only', value: 65 },
      { label: 'Know for most vendors', value: 35 },
      { label: 'Fully documented for all key vendors', value: 0 },
    ],
  },
  {
    id: 'vendor-e-6',
    dimension: 'vendorRisk',
    text: 'Have you identified which of your vendors handle your most sensitive business data?',
    helpText: 'Not all vendors carry equal risk. Knowing which vendors have access to customer PII, financial data, or IP lets you prioritize where to focus vendor risk attention.',
    type: 'radio',
    options: [
      { label: 'No formal identification done', value: 100 },
      { label: 'Informally known by some people, not documented', value: 65 },
      { label: 'Partially documented', value: 35 },
      { label: 'Clearly documented with data sensitivity levels', value: 0 },
    ],
  },
  {
    id: 'vendor-e-7',
    dimension: 'vendorRisk',
    text: 'Do you know whether your key AI vendors hold any security certifications (e.g., SOC 2)?',
    helpText: 'SOC 2 is a baseline security certification for SaaS vendors. Knowing your vendors’ certification status helps you gauge their baseline security posture.',
    type: 'radio',
    options: [
      { label: 'Not assessed — vendor certifications unknown', value: 100 },
      { label: 'Know for one or two vendors', value: 65 },
      { label: 'Know for most key vendors', value: 35 },
      { label: 'Tracked for all key vendors', value: 0 },
    ],
  },
  {
    id: 'vendor-e-8',
    dimension: 'vendorRisk',
    text: 'Has AI vendor risk come up in any purchasing or procurement discussion in your organization?',
    helpText: 'Incorporating AI risk into purchasing decisions is an early sign of governance maturity. Most organizations at this stage purchase AI tools without any structured risk check.',
    type: 'radio',
    options: [
      { label: 'No, it hasn’t come up', value: 100 },
      { label: 'Occasionally, informally', value: 65 },
      { label: 'Yes, for some purchases', value: 35 },
      { label: 'AI risk is a standard part of our purchasing process', value: 0 },
    ],
  },
  {
    id: 'vendor-e-9',
    dimension: 'vendorRisk',
    text: 'If a vendor had an AI-related data breach affecting your company data, would you know who to contact and what to do?',
    helpText: 'Even at an early stage, knowing the basics of vendor incident response (who to call, how to escalate) reduces response time significantly.',
    type: 'radio',
    options: [
      { label: 'No plan in place', value: 100 },
      { label: 'We’d figure it out in the moment', value: 65 },
      { label: 'We have vendor contacts but no documented process', value: 35 },
      { label: 'Yes, documented contacts and basic response steps', value: 0 },
    ],
  },
  {
    id: 'vendor-e-10',
    dimension: 'vendorRisk',
    text: 'Have you reviewed what happens to your data if you stop using an AI vendor’s product?',
    helpText: 'Vendor lock-in and data deletion rights are often overlooked at onboarding. Understanding exit terms prevents data being retained by vendors after offboarding.',
    type: 'radio',
    options: [
      { label: 'Never considered this', value: 100 },
      { label: 'Thought about it but haven’t checked', value: 65 },
      { label: 'Checked for our most critical vendor(s)', value: 35 },
      { label: 'Reviewed and documented exit/deletion terms for key vendors', value: 0 },
    ],
  },

  // --- Data Governance & Privacy (10) ---
  {
    id: 'data-e-1',
    dimension: 'dataGovernance',
    text: 'Do employees have any guidance on what types of information they should NOT enter into AI tools?',
    helpText: 'The simplest data governance step: telling employees "don’t paste customer names, financial figures, or health information into ChatGPT." Most organizations haven’t communicated even this.',
    type: 'radio',
    options: [
      { label: 'No guidance has been given', value: 100 },
      { label: 'Verbally mentioned but not written down', value: 65 },
      { label: 'Written guidance exists but not widely shared', value: 35 },
      { label: 'Clear written guidance shared with all employees', value: 0 },
    ],
  },
  {
    id: 'data-e-2',
    dimension: 'dataGovernance',
    text: 'Is there awareness in your organization of the risk that AI tools may store and expose company information?',
    helpText: 'Many employees treat AI chatbots like a private conversation. Building awareness that AI outputs and inputs can be stored, reviewed, or used for training is foundational.',
    type: 'radio',
    options: [
      { label: 'No awareness — not been discussed', value: 100 },
      { label: 'Some employees are aware, most aren’t', value: 65 },
      { label: 'Widely understood but not formally addressed', value: 35 },
      { label: 'Formally communicated and documented', value: 0 },
    ],
  },
  {
    id: 'data-e-3',
    dimension: 'dataGovernance',
    text: 'Does your organization have any form of data classification (e.g., public, internal, confidential)?',
    helpText: 'Even a simple 3-tier classification (public / internal / confidential) gives employees a framework to decide what can and can’t be shared with AI tools.',
    type: 'radio',
    options: [
      { label: 'No classification system exists', value: 100 },
      { label: 'Informal understanding but nothing documented', value: 65 },
      { label: 'Basic classification documented, not consistently applied', value: 35 },
      { label: 'Clear classification used by employees day-to-day', value: 0 },
    ],
  },
  {
    id: 'data-e-4',
    dimension: 'dataGovernance',
    text: 'Do you know if employees are entering customer information into AI tools?',
    helpText: '77% of employees paste company data into GenAI prompts. Customer PII in AI tools creates significant privacy and liability exposure, especially in regulated industries.',
    type: 'radio',
    options: [
      { label: 'Not assessed', value: 100 },
      { label: 'Suspected but not confirmed', value: 65 },
      { label: 'Confirmed it’s happening; haven’t addressed it', value: 35 },
      { label: 'Confirmed, and we have controls or clear guidelines in place', value: 0 },
    ],
  },
  {
    id: 'data-e-5',
    dimension: 'dataGovernance',
    text: 'Do you have basic data retention practices (how long data is kept, when it’s deleted)?',
    helpText: 'General data retention isn’t AI-specific, but it’s the foundation. AI systems often inherit retention gaps from the broader data environment.',
    type: 'radio',
    options: [
      { label: 'No retention policies exist', value: 100 },
      { label: 'Informal practices, not documented', value: 65 },
      { label: 'Basic retention policy exists for most data', value: 35 },
      { label: 'Documented retention policy, consistently applied', value: 0 },
    ],
  },
  {
    id: 'data-e-6',
    dimension: 'dataGovernance',
    text: 'Has anyone reviewed the privacy policy and data handling terms of the AI tools your organization uses?',
    helpText: 'AI vendor privacy policies describe how your data is stored, used, and whether it’s used for model training. This review takes 30 minutes per vendor and prevents significant surprises.',
    type: 'radio',
    options: [
      { label: 'No, never reviewed', value: 100 },
      { label: 'Checked for one tool', value: 65 },
      { label: 'Reviewed for most main tools', value: 35 },
      { label: 'Reviewed for all tools in active use', value: 0 },
    ],
  },
  {
    id: 'data-e-7',
    dimension: 'dataGovernance',
    text: 'Do employees know they should not enter employee personal data (HR records, salaries, performance reviews) into AI tools?',
    helpText: 'HR data is high-sensitivity. Employees using AI to draft performance reviews or process HR data often don’t consider that this information may be stored externally.',
    type: 'radio',
    options: [
      { label: 'Not addressed', value: 100 },
      { label: 'Discussed informally in HR or IT', value: 65 },
      { label: 'Part of general AI guidance', value: 35 },
      { label: 'Specific guidance exists for HR data + AI', value: 0 },
    ],
  },
  {
    id: 'data-e-8',
    dimension: 'dataGovernance',
    text: 'Do you have a process for employees to raise concerns about data being misused with AI tools?',
    helpText: 'Employees are often the first to notice misuse but don’t know where to go. A simple "report to IT or your manager" instruction reduces risk.',
    type: 'radio',
    options: [
      { label: 'No process or channel exists', value: 100 },
      { label: 'Employees can raise it informally with their manager', value: 65 },
      { label: 'There’s a general IT helpdesk or ethics channel', value: 35 },
      { label: 'Specific AI-related reporting channel or process exists', value: 0 },
    ],
  },
  {
    id: 'data-e-9',
    dimension: 'dataGovernance',
    text: 'Has your organization considered whether AI-generated content needs human review before use?',
    helpText: 'AI outputs can be incorrect, biased, or legally problematic. Even a basic "always review before sending externally" guideline significantly reduces risk.',
    type: 'radio',
    options: [
      { label: 'Not considered', value: 100 },
      { label: 'Informally understood but not communicated', value: 65 },
      { label: 'Discussed and communicated informally', value: 35 },
      { label: 'Clear guidance: AI output must be reviewed before external use', value: 0 },
    ],
  },
  {
    id: 'data-e-10',
    dimension: 'dataGovernance',
    text: 'Do you know whether your organization processes personal data of individuals in the EU or California?',
    helpText: 'GDPR (EU) and CCPA (California) apply based on whose data you process, not where your company is located. If you have EU or California customers, employees, or partners, these laws may apply.',
    type: 'radio',
    options: [
      { label: 'Not assessed', value: 100 },
      { label: 'We think so, but haven’t confirmed the legal implications', value: 65 },
      { label: 'Yes, we’re aware and have basic privacy practices', value: 35 },
      { label: 'Yes, we have documented compliance practices for applicable laws', value: 0 },
    ],
  },

  // --- Security & Compliance (10) ---
  {
    id: 'security-e-1',
    dimension: 'securityCompliance',
    text: 'Has your IT or security team reviewed the AI tools your organization is currently using?',
    helpText: 'A basic security review of AI tools — even just checking if they have SOC 2 and reviewing data handling terms — is the minimum bar for responsible adoption.',
    type: 'radio',
    options: [
      { label: 'No, IT hasn’t been involved', value: 100 },
      { label: 'IT knows about some tools but hasn’t reviewed them', value: 65 },
      { label: 'IT has informally reviewed the main tools', value: 35 },
      { label: 'IT has conducted a formal review of active AI tools', value: 0 },
    ],
  },
  {
    id: 'security-e-2',
    dimension: 'securityCompliance',
    text: 'Have you considered the security risk of employees using AI tools with company data?',
    helpText: 'AI tools can expose company data through model training, data breaches, or prompt injection attacks. Awareness of these risks is step one.',
    type: 'radio',
    options: [
      { label: 'Not considered', value: 100 },
      { label: 'Briefly thought about it, nothing done', value: 65 },
      { label: 'Discussed with leadership or IT', value: 35 },
      { label: 'Formally assessed and documented', value: 0 },
    ],
  },
  {
    id: 'security-e-3',
    dimension: 'securityCompliance',
    text: 'Do you know which industry-specific compliance requirements apply to your organization (e.g., HIPAA, PCI DSS, SOC 2)?',
    helpText: 'Compliance obligations vary by industry. Healthcare organizations must consider HIPAA. Financial services have PCI DSS. Understanding your obligations is the prerequisite for meeting them.',
    type: 'radio',
    options: [
      { label: 'Not assessed — regulations not reviewed', value: 100 },
      { label: 'Aware of some but unclear how they apply to AI', value: 65 },
      { label: 'Know our compliance obligations, haven’t assessed AI impact', value: 35 },
      { label: 'Know our obligations and have assessed how AI use affects compliance', value: 0 },
    ],
  },
  {
    id: 'security-e-4',
    dimension: 'securityCompliance',
    text: 'Are employees required to use company accounts (not personal accounts) for any AI tools they use?',
    helpText: 'Personal account usage bypasses all organizational security controls. Requiring company accounts is one of the simplest and most effective early controls.',
    type: 'radio',
    options: [
      { label: 'No requirement — employees use whatever they prefer', value: 100 },
      { label: 'Informally encouraged, not enforced', value: 65 },
      { label: 'Required for some tools, not consistently enforced', value: 35 },
      { label: 'Consistently required and enforced for all AI tools', value: 0 },
    ],
  },
  {
    id: 'security-e-5',
    dimension: 'securityCompliance',
    text: 'Is your leadership team aware of AI-specific security risks (data leakage, prompt injection, deepfakes)?',
    helpText: 'Leadership buy-in for security investment requires leadership understanding of the risk. AI introduces security threats that differ from traditional cybersecurity risks.',
    type: 'radio',
    options: [
      { label: 'Leadership is not aware', value: 100 },
      { label: 'Aware at a very high level', value: 65 },
      { label: 'Aware and have discussed implications', value: 35 },
      { label: 'Actively engaged and driving security decisions', value: 0 },
    ],
  },
  {
    id: 'security-e-6',
    dimension: 'securityCompliance',
    text: 'Do you have a cybersecurity policy that employees are required to follow?',
    helpText: 'A general cybersecurity policy is the foundation that AI-specific security policies build on. Without a baseline, AI security policies have nothing to anchor to.',
    type: 'radio',
    options: [
      { label: 'No cybersecurity policy exists', value: 100 },
      { label: 'Informal practices, not documented as a policy', value: 65 },
      { label: 'Policy exists, employees are generally aware', value: 35 },
      { label: 'Formal policy, regularly reviewed, employees acknowledge it', value: 0 },
    ],
  },
  {
    id: 'security-e-7',
    dimension: 'securityCompliance',
    text: 'Have you had any AI-related security incidents or near-misses (e.g., employee shared sensitive data, deepfake scam attempt)?',
    helpText: 'Incidents are learning opportunities. Organizations that track and learn from AI-related security events mature faster than those that don’t.',
    type: 'radio',
    options: [
      { label: ‘We’ve had incidents and haven’t tracked or learned from them’, value: 100 },
      { label: ‘Minor incidents occurred but were not formally reviewed’, value: 65 },
      { label: ‘Incidents occurred and were reviewed to improve our practices’, value: 35 },
      { label: ‘No known incidents; we actively monitor for AI-related threats’, value: 0 },
    ],
  },
  {
    id: ‘security-e-8’,
    dimension: 'securityCompliance',
    text: 'Are employees aware that AI tools can be targets for phishing, social engineering, or deepfake attacks?',
    helpText: 'AI-powered phishing is harder to detect. Deepfake voice/video impersonation is already being used in business email compromise. Basic employee awareness is a critical defense.',
    type: 'radio',
    options: [
      { label: 'Not addressed with employees', value: 100 },
      { label: 'Mentioned in general security training', value: 35 },
      { label: 'Addressed specifically in AI or security guidance', value: 35 },
      { label: 'Regular, specific training on AI-enabled threats', value: 0 },
    ],
  },
  {
    id: 'security-e-9',
    dimension: 'securityCompliance',
    text: 'Do you know if AI tool usage at your organization could affect your insurance coverage or legal liability?',
    helpText: 'Cyber insurance policies are increasingly excluding AI-related incidents or requiring specific controls. Legal liability from AI errors or data exposure is a growing concern.',
    type: 'radio',
    options: [
      { label: 'Haven’t considered this', value: 100 },
      { label: 'Vaguely aware but haven’t looked into it', value: 65 },
      { label: 'Discussed with legal or insurance contacts', value: 35 },
      { label: 'Reviewed and documented our AI-related coverage and liability exposure', value: 0 },
    ],
  },
  {
    id: 'security-e-10',
    dimension: 'securityCompliance',
    text: 'Do you have a basic process for employees to report a security incident involving an AI tool?',
    helpText: 'Incident reporting starts with knowing who to call. Even "email IT immediately if you think something went wrong" is better than no process.',
    type: 'radio',
    options: [
      { label: 'No process — employees wouldn’t know what to do', value: 100 },
      { label: 'General IT helpdesk exists but not AI-specific', value: 35 },
      { label: 'Employees know to escalate AI security concerns to IT', value: 35 },
      { label: 'Documented AI incident reporting process, employees trained', value: 0 },
    ],
  },

  // --- AI-Specific Risks (10) ---
  {
    id: 'airisks-e-1',
    dimension: 'aiSpecificRisks',
    text: 'Are employees aware that AI tools can produce incorrect or fabricated information (hallucinations)?',
    helpText: 'AI hallucinations — where the AI confidently states false information — are common. Employees who don’t know this will trust AI outputs they shouldn’t.',
    type: 'radio',
    options: [
      { label: 'Most employees are not aware of this', value: 100 },
      { label: 'Some know, most don’t', value: 65 },
      { label: 'Generally understood, not formally addressed', value: 35 },
      { label: 'Formally communicated as part of AI guidance', value: 0 },
    ],
  },
  {
    id: 'airisks-e-2',
    dimension: 'aiSpecificRisks',
    text: 'Do you have any guidance about reviewing AI-generated content before using it?',
    helpText: 'The simplest risk control: require that AI outputs are reviewed by a human before being used in decisions, communications, or documents. Even a basic policy helps.',
    type: 'radio',
    options: [
      { label: 'No guidance — employees use AI outputs as-is', value: 100 },
      { label: 'Informal expectation to review, not communicated', value: 65 },
      { label: 'Basic guidance communicated to some teams', value: 35 },
      { label: 'Clear review requirement communicated to all employees', value: 0 },
    ],
  },
  {
    id: 'airisks-e-3',
    dimension: 'aiSpecificRisks',
    text: 'Have you had any instances where AI tools produced incorrect or problematic outputs that caused an issue?',
    helpText: 'Learning from AI errors before they cause significant harm is an important governance milestone. Tracking and discussing these events improves future practice.',
    type: 'radio',
    options: [
      { label: 'Yes, and we didn’t track or learn from it', value: 100 },
      { label: 'Not that we’re aware of', value: 35 },
      { label: 'Yes, but it was minor and handled informally', value: 65 },
      { label: 'Yes — we documented it and updated our practices', value: 0 },
    ],
  },
  {
    id: 'airisks-e-4',
    dimension: 'aiSpecificRisks',
    text: 'Are employees using AI to generate customer-facing content without human review?',
    helpText: 'AI-generated customer communications, marketing copy, or support responses that go out unreviewed represent significant reputational and legal risk.',
    type: 'radio',
    options: [
      { label: 'Yes, and we don’t have oversight', value: 100 },
      { label: 'Probably happening but we haven’t checked', value: 65 },
      { label: 'Aware of some cases, informally managed', value: 35 },
      { label: 'Customer-facing AI content requires human review — enforced', value: 0 },
    ],
  },
  {
    id: 'airisks-e-5',
    dimension: 'aiSpecificRisks',
    text: 'Are employees aware that AI can produce biased outputs, especially in areas like hiring, lending, or customer service?',
    helpText: 'AI bias can result in discriminatory outcomes in hiring, credit decisions, or customer treatment. Awareness of this risk is the starting point for managing it.',
    type: 'radio',
    options: [
      { label: 'Not addressed — most employees are unaware', value: 100 },
      { label: 'Some awareness in technical teams', value: 65 },
      { label: 'Discussed across the organization', value: 35 },
      { label: 'Formally addressed with guidance on high-risk AI uses', value: 0 },
    ],
  },
  {
    id: 'airisks-e-6',
    dimension: 'aiSpecificRisks',
    text: 'Do you have any guidelines about using AI tools for important business decisions?',
    helpText: 'AI is most valuable as a decision support tool, not a decision-maker. Guidelines that require human judgment for significant decisions reduce risk substantially.',
    type: 'radio',
    options: [
      { label: 'No guidelines — employees use AI however they choose', value: 100 },
      { label: 'Informal expectation, not communicated', value: 65 },
      { label: 'Basic guidance communicated to some teams', value: 35 },
      { label: 'Clear guidelines: AI assists, humans decide on important matters', value: 0 },
    ],
  },
  {
    id: 'airisks-e-7',
    dimension: 'aiSpecificRisks',
    text: 'Have you assessed whether AI tool usage could expose your organization to copyright or intellectual property issues?',
    helpText: 'AI-generated content may inadvertently reproduce copyrighted material. AI coding assistants may generate code that resembles licensed code. These risks are not widely understood.',
    type: 'radio',
    options: [
      { label: 'Not considered', value: 100 },
      { label: 'Aware of the risk, haven’t assessed it', value: 65 },
      { label: 'Discussed with legal or technical team', value: 35 },
      { label: 'Assessed and have guidance in place for high-risk use cases', value: 0 },
    ],
  },
  {
    id: 'airisks-e-8',
    dimension: 'aiSpecificRisks',
    text: 'Do employees know when to seek a second opinion or escalate concerns about AI outputs?',
    helpText: 'Even without a formal escalation path, employees knowing "if something seems wrong with an AI output, raise it" prevents small errors from becoming big problems.',
    type: 'radio',
    options: [
      { label: 'No guidance — employees are on their own', value: 100 },
      { label: 'Informal expectation that they’d just ask a colleague', value: 65 },
      { label: 'Employees know to flag concerns to IT or their manager', value: 35 },
      { label: 'Clear escalation path communicated to all employees', value: 0 },
    ],
  },
  {
    id: 'airisks-e-9',
    dimension: 'aiSpecificRisks',
    text: 'Have you thought about the reputational risk if AI errors become visible to customers or the public?',
    helpText: 'A customer receiving AI-generated misinformation, a biased decision, or a privacy breach from AI use can cause lasting reputational damage. Leadership awareness of this risk matters.',
    type: 'radio',
    options: [
      { label: 'Not on anyone’s radar', value: 100 },
      { label: 'Casually discussed but not formally considered', value: 65 },
      { label: 'Included in risk discussions at leadership level', value: 35 },
      { label: 'Formally assessed and included in business risk management', value: 0 },
    ],
  },
  {
    id: 'airisks-e-10',
    dimension: 'aiSpecificRisks',
    text: 'Is there any monitoring of AI tool usage to detect potential misuse or inappropriate outputs?',
    helpText: 'At the Experimenter stage, monitoring doesn’t need to be technical — even a regular check-in where employees can surface concerns is a step forward.',
    type: 'radio',
    options: [
      { label: 'No monitoring of any kind', value: 100 },
      { label: 'Relying entirely on employees to self-report', value: 65 },
      { label: 'Manager check-ins or periodic team discussions', value: 35 },
      { label: 'Structured monitoring process, even if lightweight', value: 0 },
    ],
  },

  // --- ROI Tracking (10) ---
  {
    id: 'roi-e-1',
    dimension: 'roiTracking',
    text: 'Are you tracking whether AI tools are saving employees time?',
    helpText: 'Time savings are the most common and easiest AI benefit to measure. Even asking employees "how much time does this save you per week?" provides useful data.',
    type: 'radio',
    options: [
      { label: 'No tracking of any kind', value: 100 },
      { label: 'Employees report time savings informally', value: 65 },
      { label: 'We’ve asked in surveys or conversations', value: 35 },
      { label: 'We actively track time savings from AI use', value: 0 },
    ],
  },
  {
    id: 'roi-e-2',
    dimension: 'roiTracking',
    text: 'Do you have a sense of how much your organization is spending on AI tool subscriptions?',
    helpText: 'AI spend is often fragmented across teams with individual credit cards or expense accounts. Aggregating AI spend is step one in understanding ROI.',
    type: 'radio',
    options: [
      { label: 'Not assessed — no central tracking', value: 100 },
      { label: 'Rough ballpark, not fully aggregated', value: 65 },
      { label: 'Know the main subscriptions, some gaps', value: 35 },
      { label: 'Full visibility into AI spend across the organization', value: 0 },
    ],
  },
  {
    id: 'roi-e-3',
    dimension: 'roiTracking',
    text: 'Do you know which AI tools employees are actually using versus tools you’re paying for but that go unused?',
    helpText: 'AI subscription waste is common — organizations often pay for licenses that aren’t being used. A quick utilization check often surfaces quick cost savings.',
    type: 'radio',
    options: [
      { label: 'No visibility into utilization', value: 100 },
      { label: 'Anecdotal sense but no data', value: 65 },
      { label: 'Some visibility for major subscriptions', value: 35 },
      { label: 'Track utilization across AI subscriptions', value: 0 },
    ],
  },
  {
    id: 'roi-e-4',
    dimension: 'roiTracking',
    text: 'Have you had a conversation about what business value you expect to get from AI adoption?',
    helpText: 'Without a stated expected value, there’s no way to measure success. Even an informal conversation — "we think AI will save us X hours per week" — creates accountability.',
    type: 'radio',
    options: [
      { label: 'No conversation has happened', value: 100 },
      { label: 'Vague expectations, nothing quantified', value: 65 },
      { label: 'Had a conversation, general alignment on goals', value: 35 },
      { label: 'Specific value expectations articulated and documented', value: 0 },
    ],
  },
  {
    id: 'roi-e-5',
    dimension: 'roiTracking',
    text: 'Are employees reporting productivity improvements from using AI tools?',
    helpText: 'Employee-reported productivity gains are an informal but valuable early signal. Collecting these stories builds the business case for further investment.',
    type: 'radio',
    options: [
      { label: 'No one has asked or is tracking this', value: 100 },
      { label: 'Some employees share anecdotes informally', value: 65 },
      { label: 'We’ve asked and collected some feedback', value: 35 },
      { label: 'We systematically collect and track employee-reported gains', value: 0 },
    ],
  },
  {
    id: 'roi-e-6',
    dimension: 'roiTracking',
    text: 'Do you know if AI tools are reducing errors in any of your business processes?',
    helpText: 'Error reduction is one of the highest-value AI benefits, especially in data entry, document review, or repetitive processes. Many organizations don’t think to measure it.',
    type: 'radio',
    options: [
      { label: 'Not tracking this', value: 100 },
      { label: 'Anecdotally believed but not measured', value: 65 },
      { label: 'Measured informally for one or two use cases', value: 35 },
      { label: 'Actively tracking error rates in AI-assisted processes', value: 0 },
    ],
  },
  {
    id: 'roi-e-7',
    dimension: 'roiTracking',
    text: 'Is there a person or team responsible for AI spending and budget?',
    helpText: 'Without a budget owner, AI spending sprawls uncontrolled and ROI accountability doesn’t exist. Even designating "IT manages AI subscriptions" is a meaningful step.',
    type: 'radio',
    options: [
      { label: 'No one has this responsibility', value: 100 },
      { label: 'Various department heads manage their own AI spend', value: 65 },
      { label: 'One function loosely coordinates AI spending', value: 35 },
      { label: 'Clear budget owner with visibility into all AI spend', value: 0 },
    ],
  },
  {
    id: 'roi-e-8',
    dimension: 'roiTracking',
    text: 'Have you thought about how AI adoption might be affecting your competitive position?',
    helpText: 'Competitors adopting AI faster can improve cost structure, speed, and product quality. Understanding competitive dynamics motivates appropriate investment pace.',
    type: 'radio',
    options: [
      { label: 'Not considered', value: 100 },
      { label: 'Generally aware but no structured thinking', value: 65 },
      { label: 'Discussed at leadership level', value: 35 },
      { label: 'Part of our strategic planning process', value: 0 },
    ],
  },
  {
    id: 'roi-e-9',
    dimension: 'roiTracking',
    text: 'Have you made any attempt to estimate or calculate a return on AI investment, even informally?',
    helpText: 'Even a back-of-napkin calculation ("we saved 10 hours/week × $50/hour × 52 weeks = $26K/year") builds the discipline of measuring AI value.',
    type: 'radio',
    options: [
      { label: 'No estimate of any kind', value: 100 },
      { label: 'Vague sense that it’s worth it but no numbers', value: 65 },
      { label: 'Rough informal calculation done', value: 35 },
      { label: 'Formal or semi-formal ROI estimate created', value: 0 },
    ],
  },
  {
    id: 'roi-e-10',
    dimension: 'roiTracking',
    text: 'Do you track whether AI tools are helping with customer satisfaction or experience?',
    helpText: 'AI can improve customer response times, personalization, and service quality. Tracking customer satisfaction metrics for AI-assisted interactions builds the case for expansion.',
    type: 'radio',
    options: [
      { label: 'Not tracking', value: 100 },
      { label: 'General CSAT tracking, not AI-specific', value: 65 },
      { label: 'Aware of AI impact informally from customer feedback', value: 35 },
      { label: 'Tracking customer metrics specifically for AI-assisted interactions', value: 0 },
    ],
  },
];
